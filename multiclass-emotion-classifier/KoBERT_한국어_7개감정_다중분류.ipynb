{"cells":[{"cell_type":"markdown","metadata":{"id":"JN0MExMGFJXa"},"source":["## 라이브러리 설치"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27570,"status":"ok","timestamp":1670510529028,"user":{"displayName":"서나","userId":"08132962974272332224"},"user_tz":-540},"id":"ji-W5_BIH0Rn","outputId":"b28dd009-f304-40e2-f823-ff427c132830"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[K     |████████████████████████████████| 49.1 MB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (1.21.6)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (2.23.0)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 27.2 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->gluonnlp) (3.0.9)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp38-cp38-linux_x86_64.whl size=619633 sha256=c9793d90b9c214940ad83094cdce9102d318676888083b60756d3c49523ed31c\n","  Stored in directory: /root/.cache/pip/wheels/b6/93/9d/2237550c409eb3ed725d6302b7897ddd9a037b40cef66dcd9c\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 34.0 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 26.1 MB/s \n","\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (0.1.97)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers==3.0.2) (1.21.6)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 68.6 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 56.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=ca257496929cba84d2fcafeb1368ab69557e07868da46afac861bed8fdd72ecc\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.8.1rc1 transformers-3.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"]}],"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","!pip install torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3204,"status":"ok","timestamp":1670510532223,"user":{"displayName":"서나","userId":"08132962974272332224"},"user_tz":-540},"id":"_Ory8tgcHq2V","outputId":"d55cd281-3092-4643-fee8-b89468f9945c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"]}],"source":["!pip install pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132706,"status":"ok","timestamp":1670510664913,"user":{"displayName":"서나","userId":"08132962974272332224"},"user_tz":-540},"id":"kPIzE45lKmRX","outputId":"5e318aef-e6e4-47a1-ccb7-8f40c72548f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-8gyqeq68\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-8gyqeq68\n","Collecting boto3<=1.15.18\n","  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n","\u001b[K     |████████████████████████████████| 129 kB 32.7 MB/s \n","\u001b[?25hRequirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (0.10.0)\n","Collecting mxnet<=1.7.0.post2,>=1.4.0\n","  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n","\u001b[K     |████████████████████████████████| 54.7 MB 34 kB/s \n","\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n","  Downloading onnxruntime-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[K     |████████████████████████████████| 4.5 MB 66.3 MB/s \n","\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n","  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 47.7 MB/s \n","\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n","  Downloading torch-1.10.1-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.3 MB/s eta 0:00:39tcmalloc: large alloc 1147494400 bytes == 0x398d2000 @  0x7f0119d38615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n","\u001b[K     |████████████████████████████████| 881.9 MB 8.5 kB/s \n","\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n","  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 62.0 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.6)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 2.2 MB/s \n","\u001b[?25hCollecting botocore<1.19.0,>=1.18.18\n","  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n","\u001b[K     |████████████████████████████████| 6.7 MB 66.3 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n","Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.9.24)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.4.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.53)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 53.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.2.0)\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=d6b4997ad3e7981fdbf41f7e4cc10dc3bee788719cb9dfab419aefc310306c61\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-uqgguw96/wheels/bf/5f/74/81bf3a1332130eb6629ecf58876a8746b77021e7d7b0638e91\n","Successfully built kobert\n","Installing collected packages: jmespath, botocore, tokenizers, s3transfer, huggingface-hub, transformers, torch, sentencepiece, onnxruntime, mxnet, boto3, kobert\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.8.1rc1\n","    Uninstalling tokenizers-0.8.1rc1:\n","      Successfully uninstalled tokenizers-0.8.1rc1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 3.0.2\n","    Uninstalling transformers-3.0.2:\n","      Successfully uninstalled transformers-3.0.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.0+cu116\n","    Uninstalling torch-1.13.0+cu116:\n","      Successfully uninstalled torch-1.13.0+cu116\n","  Attempting uninstall: sentencepiece\n","    Found existing installation: sentencepiece 0.1.97\n","    Uninstalling sentencepiece-0.1.97:\n","      Successfully uninstalled sentencepiece-0.1.97\n","  Attempting uninstall: mxnet\n","    Found existing installation: mxnet 1.9.1\n","    Uninstalling mxnet-1.9.1:\n","      Successfully uninstalled mxnet-1.9.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.10.1 which is incompatible.\n","torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.10.1 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.15.18 botocore-1.18.18 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n"]}],"source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2VMYT4yKyIq"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghVmDmppKz3s"},"outputs":[],"source":["from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I16yZooVK8aG"},"outputs":[],"source":["from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f11McEJK94Y"},"outputs":[],"source":["##GPU 사용 시\n","device = torch.device(\"cuda:0\")\n","\n","##CPU 사용 시\n","#device=torch.device('cpu') "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xo32cy6UK_1I","executionInfo":{"status":"ok","timestamp":1670510692569,"user_tz":-540,"elapsed":17409,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"6b40c543-4586-43e8-8322-ee52fe7cacc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"]}],"source":["bertmodel, vocab = get_pytorch_kobert_model()"]},{"cell_type":"markdown","metadata":{"id":"qVtgNka_kpCX"},"source":["## 한국어 대화 데이터 불러오기 & 전처리\n","https://aihub.or.kr/keti_data_board/language_intelligence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c47WPgPXLCKG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510718028,"user_tz":-540,"elapsed":25466,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"3c641e8b-006c-496a-f2df-97b6710b4242"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#구글드라이브 연동\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jm75TGWxKqmt"},"outputs":[],"source":["import pandas as pd\n","chatbot_data = pd.read_excel('/content/drive/MyDrive/졸프 스타트/2022-2_프로젝트 관련/한국어_단발성_대화_데이터셋.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvXSOK6-iGdB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510724877,"user_tz":-540,"elapsed":29,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"d49191a8-c518-49b4-99af-5b3e9f4e763d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["79473"]},"metadata":{},"execution_count":12}],"source":["len(chatbot_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"095TChzwMY8L","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1670510724877,"user_tz":-540,"elapsed":24,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"8dc57a6b-7fcb-418c-f2ae-120a2ebd902e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              Sentence Emotion  Unnamed: 2  \\\n","56062                                  선발진은 거의 두산 맞먹네.      놀람         NaN   \n","11562                        이번 모의고사는 일 등급이 나올 것이 확실해.      행복         NaN   \n","17363            업무량이 너무 많았는데 타 부서에서 도움을 주겠다고 해서 다행이야.      행복         NaN   \n","36000  내 또래의 중년 남성이 과로사로 쓰러져 회복하기 힘들대. 가족 인터뷰가 너무 슬펐어.      슬픔         NaN   \n","41332          내가 따돌림 당한다는 사실을 언니가 진지하게 들어주지 않아서 낙담했어.      슬픔         NaN   \n","69551                                      술을 끊는게 맞겠죠?      공포         NaN   \n","52785                           은퇴 후 장사를 시작했는데 쉽지가 않네.      분노         NaN   \n","46045               서로 최순실 모른다고 잡아떼지만 한통속으로 보는 내가 바보냐?      분노         NaN   \n","13442                           나이 들면서 세상을 보는 눈이 넓어졌어.      행복         NaN   \n","37265   어렸을 때부터 몸이 안 좋아서 건강에 비정상적으로 집착하는 내 모습에 환멸을 느껴.      슬픔         NaN   \n","\n","       Unnamed: 3  Unnamed: 4 Unnamed: 5 Unnamed: 6  \n","56062         NaN         NaN        NaN        NaN  \n","11562         NaN         NaN        NaN        NaN  \n","17363         NaN         NaN        NaN        NaN  \n","36000         NaN         NaN        NaN        NaN  \n","41332         NaN         NaN        NaN        NaN  \n","69551         NaN         NaN        NaN        NaN  \n","52785         NaN         NaN        NaN        NaN  \n","46045         NaN         NaN        NaN        NaN  \n","13442         NaN         NaN        NaN        NaN  \n","37265         NaN         NaN        NaN        NaN  "],"text/html":["\n","  <div id=\"df-c1593179-adfd-4518-ace2-7eee4adb533c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Emotion</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","      <th>Unnamed: 5</th>\n","      <th>Unnamed: 6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>56062</th>\n","      <td>선발진은 거의 두산 맞먹네.</td>\n","      <td>놀람</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11562</th>\n","      <td>이번 모의고사는 일 등급이 나올 것이 확실해.</td>\n","      <td>행복</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>17363</th>\n","      <td>업무량이 너무 많았는데 타 부서에서 도움을 주겠다고 해서 다행이야.</td>\n","      <td>행복</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>36000</th>\n","      <td>내 또래의 중년 남성이 과로사로 쓰러져 회복하기 힘들대. 가족 인터뷰가 너무 슬펐어.</td>\n","      <td>슬픔</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>41332</th>\n","      <td>내가 따돌림 당한다는 사실을 언니가 진지하게 들어주지 않아서 낙담했어.</td>\n","      <td>슬픔</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>69551</th>\n","      <td>술을 끊는게 맞겠죠?</td>\n","      <td>공포</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>52785</th>\n","      <td>은퇴 후 장사를 시작했는데 쉽지가 않네.</td>\n","      <td>분노</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>46045</th>\n","      <td>서로 최순실 모른다고 잡아떼지만 한통속으로 보는 내가 바보냐?</td>\n","      <td>분노</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>13442</th>\n","      <td>나이 들면서 세상을 보는 눈이 넓어졌어.</td>\n","      <td>행복</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>37265</th>\n","      <td>어렸을 때부터 몸이 안 좋아서 건강에 비정상적으로 집착하는 내 모습에 환멸을 느껴.</td>\n","      <td>슬픔</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1593179-adfd-4518-ace2-7eee4adb533c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c1593179-adfd-4518-ace2-7eee4adb533c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c1593179-adfd-4518-ace2-7eee4adb533c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}],"source":["chatbot_data.sample(n=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvpjgx_LofQk"},"outputs":[],"source":["chatbot_data.loc[(chatbot_data['Emotion'] == \"공포\"), 'Emotion'] = 0  #공포 => 0\n","chatbot_data.loc[(chatbot_data['Emotion'] == \"놀람\"), 'Emotion'] = 1  #놀람 => 1\n","chatbot_data.loc[(chatbot_data['Emotion'] == \"분노\"), 'Emotion'] = 2  #분노 => 2\n","chatbot_data.loc[(chatbot_data['Emotion'] == \"슬픔\"), 'Emotion'] = 3  #슬픔 => 3\n","chatbot_data.loc[(chatbot_data['Emotion'] == \"중립\"), 'Emotion'] = 4  #중립 => 4\n","chatbot_data.loc[(chatbot_data['Emotion'] == \"행복\"), 'Emotion'] = 5  #행복 => 5\n","chatbot_data.loc[(chatbot_data['Emotion'] == \"혐오\"), 'Emotion'] = 6  #혐오 => 6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BT1_EM47QuOs"},"outputs":[],"source":["data_list = []\n","for q, label in zip(chatbot_data['Sentence'], chatbot_data['Emotion'])  :\n","    data = []\n","    data.append(q)\n","    data.append(str(label))\n","\n","    data_list.append(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6fzTfcyPs5-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510725476,"user_tz":-540,"elapsed":12,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"91229ede-21bf-44dd-aa07-57ce4bb931b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["79473\n","['저러니까 자신보다 어린 사람한테 미개하다는 소리듣지', '6']\n","['아이고 방귀문이랑 바끄네가 슬퍼하겠네...', '6']\n","['8. 꽃들고 사랑한다고 말해주기9.', '5']\n","['변기에 앉아서 읽고있당', '4']\n","['오늘 친구와 크게 다퉜는데 생각해보면 내가 잘못한 것 같아 사과하고 싶어.', '3']\n","['무한도전이 진심 재미있어?', '1']\n","['친구 관계가 너무 힘들어. 베푸는 만큼 돌아오지 않는 것 같아.', '0']\n"]}],"source":["print(len(data_list))\n","print(data_list[0])\n","print(data_list[1000])\n","print(data_list[10000])\n","print(data_list[20000])\n","print(data_list[40000])\n","print(data_list[60000])\n","print(data_list[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZkiPnBAqTPmm"},"outputs":[],"source":["#train & test 데이터로 나누기\n","from sklearn.model_selection import train_test_split\n","\n","dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Im8B3utpTol4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510725476,"user_tz":-540,"elapsed":10,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"1f06e8a1-d6c2-43dc-87d2-bdb5e047cb67"},"outputs":[{"output_type":"stream","name":"stdout","text":["59604\n","19869\n","['옆집 순이 할머니는 이 억이나 모았다는데 나는 반도 못 모았어.', '1']\n","['망겜 드디어 가네ㅋㅋㅋㅋ', '5']\n"]}],"source":["print(len(dataset_train))\n","print(len(dataset_test))\n","print(dataset_train[0])\n","print(dataset_test[0])"]},{"cell_type":"markdown","metadata":{"id":"SogQYv5dk5yL"},"source":["## 학습모델"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UU_rr0FaLNzS"},"outputs":[],"source":["class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09286PSOLb7p"},"outputs":[],"source":["## Setting parameters\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 5\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uK9v46UwLMvq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510725477,"user_tz":-540,"elapsed":8,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"f3259453-155d-43f1-c12d-eac69f24010a"},"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}],"source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BvMOyj6ELeBx"},"outputs":[],"source":["data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n","data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NuYZAQBDpGt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510730727,"user_tz":-540,"elapsed":16,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"2ac8524f-cf0f-4126-f2f0-26b3628557a3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([   2, 3395, 7354, 2912, 7096, 4979, 5760, 3647,  517, 6858, 7098,\n","        2062, 5761, 1375, 2207, 5859, 2086, 2044, 6827, 6855,  517,   54,\n","           3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n"," array(23, dtype=int32),\n"," array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       dtype=int32),\n"," 1)"]},"metadata":{},"execution_count":23}],"source":["data_train[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7EngEL1HZLdE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510730728,"user_tz":-540,"elapsed":15,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"04ae02a3-c706-4485-ced3-9e8261fd620e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([   2, 3489, 3886, 5628, 1841, 4814, 6797, 6553, 1730, 1598, 5439,\n","        4930, 3107, 1849, 5213, 6855,  517,    5,    3,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n"," array(19, dtype=int32),\n"," array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       dtype=int32),\n"," 2)"]},"metadata":{},"execution_count":24}],"source":["data_test[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9mp6NBk8Lfia","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510730728,"user_tz":-540,"elapsed":14,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"c67bf1a4-2833-4d77-ec64-5b5a77effc29"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTmnY0GPLgzk"},"outputs":[],"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=7,\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), \n","                              attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbCay-MELjSK"},"outputs":[],"source":["model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMPpt1-dLli-"},"outputs":[],"source":["# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S5DTOmekLn_N"},"outputs":[],"source":["optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lxTq9gyLugi"},"outputs":[],"source":["t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EQMvJKyVLvqd"},"outputs":[],"source":["scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LG7OxbEVLxED"},"outputs":[],"source":["def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9uTbJC8D7Ef","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510735373,"user_tz":-540,"elapsed":27,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"972809ab-6e29-42c2-cd87-d1b976177b0c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x7efcbda37af0>"]},"metadata":{},"execution_count":33}],"source":["train_dataloader"]},{"cell_type":"markdown","metadata":{"id":"BtFH9umMlA8g"},"source":["## 학습시키기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNHnnosOLyLX","colab":{"base_uri":"https://localhost:8080/","height":511,"referenced_widgets":["96b83584b9ef465fa5af9af1430ba3f0","9eecf8a2ac0b475680b8da064dec8c60","9bbc228adaa44090b8a2c630d11515f4","5bbf7229820c4fa5b0f2e0704a466181","2314c368a1bd4c5f853cc1e0a7f142bc","417d2d97979c440087ad1963f448b2b6","ad431dc1214f48e7aef6326f606ae569","6fe775eb86154b64a3964bb96ee0daf2","98b00914873e422198dde95d9bd1d1af","f28e4ee25ce044deb54120f03cf99581","a6f31b255d93425ea8143ccd102f9446"]},"executionInfo":{"status":"error","timestamp":1670510890766,"user_tz":-540,"elapsed":155417,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"d9cca133-1a29-4fe6-8e4c-901bf100040a"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-34-480b6a139979>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/932 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96b83584b9ef465fa5af9af1430ba3f0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 1 batch id 1 loss 1.9846618175506592 train acc 0.0625\n","epoch 1 batch id 201 loss 1.4471083879470825 train acc 0.2573072139303483\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-480b6a139979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for e in range(num_epochs):\n","    train_acc = 0.0\n","    test_acc = 0.0\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","    \n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        test_acc += calc_accuracy(out, label)\n","    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"]},{"cell_type":"markdown","metadata":{"id":"-ugfFLvsCkki"},"source":["## 모델 저장하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HE-xIRaQ-0UY"},"outputs":[],"source":["#구글드라이브 연동(여기서부터 시작할때)\n","#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-U4Ok3K8-CR"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/졸프 스타트/2022-2_프로젝트 관련/NLP관련_서영/')\n","os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pk1lODhYL1Ay"},"outputs":[],"source":["path = '/content/drive/MyDrive/졸프 스타트/2022-2_프로젝트 관련/NLP관련_서영/'\n","torch.save(model, path + '7emotions_model.pt')  # 전체 모델 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_4i0UK5Afs-"},"outputs":[],"source":["torch.save(model.state_dict(), '7emotions_model_state_dict.pt')  # 모델 객체의 state_dict 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4XrDmlnAmcg"},"outputs":[],"source":["torch.save({\n","    'model': model.state_dict(),\n","    'optimizer': optimizer.state_dict()\n","}, '7emotions_all.tar')  # 여러 가지 값 저장, 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar값 저장 가능"]},{"cell_type":"markdown","metadata":{"id":"ogJT46r4lZ3-"},"source":["## 모델 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEYtiowYE8Vz"},"outputs":[],"source":["#구글드라이브 연동\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNsuFGn-A8zt"},"outputs":[],"source":["#★★★현재경로가 model이 있는 폴더여야함★★★\n","#학습모델의 bertclassifier 실행시켜야함.\n","import os\n","os.chdir('/content/drive/MyDrive/졸프 스타트/2022-2_프로젝트 관련/NLP관련_서영/model/')\n","\n","##cpu사용시\n","#model = torch.load('/content/drive/MyDrive/졸프 스타트/2022-2_프로젝트 관련/NLP관련_서영/model/7emotions_model.pt', map_location=lambda storage, loc: storage)\n","#model.load_state_dict(torch.load('/content/drive/MyDrive/졸프 스타트/2022-2_프로젝트 관련/NLP관련_서영/model/7emotions_model_state_dict.pt', map_location=device))\n","#checkpoint = torch.load('/content/drive/MyDrive/졸프 스타트/2022-2_프로젝트 관련/NLP관련_서영/model/7emotions_all.tar', map_location=lambda storage, loc: storage)\n","#model.load_state_dict(checkpoint['model'])\n","#optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","model = torch.load('7emotions_model.pt')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n","model.load_state_dict(torch.load('7emotions_model_state_dict.pt'))  # state_dict를 불러 온 후, 모델에 저장\n","\n","checkpoint = torch.load('7emotions_all.tar')   # dict 불러오기\n","model.load_state_dict(checkpoint['model'])\n","optimizer.load_state_dict(checkpoint['optimizer'])"]},{"cell_type":"markdown","metadata":{"id":"YgJME-pAC-OE"},"source":["## 테스트"]},{"cell_type":"markdown","metadata":{"id":"1L8JuqgiRvhA"},"source":["### 테스트\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZB2xcQLGH5g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670510927430,"user_tz":-540,"elapsed":1059,"user":{"displayName":"서나","userId":"08132962974272332224"}},"outputId":"26cb0350-3011-42e3-8a59-9bb0eacba40b"},"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model. /content/drive/MyDrive/졸프 스타트/2022-2_프로젝트 관련/NLP관련_서영/model/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}],"source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DhtMYhBrKcoP"},"outputs":[],"source":["def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","\n","            if np.argmax(logits) == 0:\n","                test_eval.append(\"공포가\")\n","            elif np.argmax(logits) == 1:\n","                test_eval.append(\"놀람이\")\n","            elif np.argmax(logits) == 2:\n","                test_eval.append(\"분노가\")\n","            elif np.argmax(logits) == 3:\n","                test_eval.append(\"슬픔이\")\n","            elif np.argmax(logits) == 4:\n","                test_eval.append(\"중립이\")\n","            elif np.argmax(logits) == 5:\n","                test_eval.append(\"행복이\")\n","            elif np.argmax(logits) == 6:\n","                test_eval.append(\"혐오가\")\n","\n","        print(test_eval[0] + \" 느껴집니다.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KeyHXLcwUjpw"},"outputs":[],"source":["#질문 무한반복하기!\n","end = 1\n","while end == 1 :\n","    sentence = input(\"말을 입력해주세요 : \")\n","    if sentence == 0 :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1XVELYqh4NT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8e1a598-a999-4800-bde6-69666869ee95"},"outputs":[{"output_type":"stream","name":"stdout","text":["말을 입력해주세요 : 벌써 3일 밤을 샜어. 너무 피곤해\n","슬픔이 느껴집니다.\n","\n","\n","말을 입력해주세요 : 집에 가면 따뜻한 밥을 먹을 수 있을거야. 조금만 더 힘내자\n","행복이 느껴집니다.\n","\n","\n","말을 입력해주세요 : 오늘은 힘든 날이었어. 아침부터 공부도 잘 안되고..\n","슬픔이 느껴집니다.\n","\n","\n","말을 입력해주세요 : 빨리 시험이 끝나서 팀원들이랑 맛있는 밥을 먹자\n","행복이 느껴집니다.\n","\n","\n"]}],"source":["#질문 무한반복하기!\n","end = 1\n","while end == 1 :\n","    sentence = input(\"말을 입력해주세요 : \")\n","    if sentence == 0 :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8ETDrIRbswe"},"outputs":[],"source":["#질문 무한반복하기!\n","end = 1\n","while end == 1 :\n","    sentence = input(\"말을 입력해주세요 : \")\n","    if sentence == 0 :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"]},{"cell_type":"code","source":["#질문 무한반복하기!\n","end = 1\n","while end == 1 :\n","    sentence = input(\"말을 입력해주세요 : \")\n","    if sentence == 0 :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"],"metadata":{"id":"M9JSEGeW9Huz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#질문 무한반복하기!\n","end = 1\n","while end == 1 :\n","    sentence = input(\"말을 입력해주세요 : \")\n","    if sentence == 0 :\n","        break\n","    predict(sentence)\n","    print(\"\\n\")"],"metadata":{"id":"H7MtY8Vq9R2x"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["-ugfFLvsCkki","ogJT46r4lZ3-","YgJME-pAC-OE","kfFYXMZRRtOn","1L8JuqgiRvhA"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"96b83584b9ef465fa5af9af1430ba3f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9eecf8a2ac0b475680b8da064dec8c60","IPY_MODEL_9bbc228adaa44090b8a2c630d11515f4","IPY_MODEL_5bbf7229820c4fa5b0f2e0704a466181"],"layout":"IPY_MODEL_2314c368a1bd4c5f853cc1e0a7f142bc"}},"9eecf8a2ac0b475680b8da064dec8c60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_417d2d97979c440087ad1963f448b2b6","placeholder":"​","style":"IPY_MODEL_ad431dc1214f48e7aef6326f606ae569","value":" 23%"}},"9bbc228adaa44090b8a2c630d11515f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fe775eb86154b64a3964bb96ee0daf2","max":932,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98b00914873e422198dde95d9bd1d1af","value":215}},"5bbf7229820c4fa5b0f2e0704a466181":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f28e4ee25ce044deb54120f03cf99581","placeholder":"​","style":"IPY_MODEL_a6f31b255d93425ea8143ccd102f9446","value":" 215/932 [02:35&lt;08:43,  1.37it/s]"}},"2314c368a1bd4c5f853cc1e0a7f142bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"417d2d97979c440087ad1963f448b2b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad431dc1214f48e7aef6326f606ae569":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fe775eb86154b64a3964bb96ee0daf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98b00914873e422198dde95d9bd1d1af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f28e4ee25ce044deb54120f03cf99581":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6f31b255d93425ea8143ccd102f9446":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}